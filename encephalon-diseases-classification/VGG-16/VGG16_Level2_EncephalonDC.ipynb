{"cells":[{"cell_type":"markdown","source":["#**Encephalon Diseases Classifier**\n","Is a multi-level project where more than one step of classification is performed on a dataset that contains MRI scans of control subjets, Alzheimer's disease, Parkinson's disease, and brain tumors.\n","\n","---\n","\n","##**Encephalon Dataset**\n","The dataset used in this project is a combintion of three different datasets. These datasets are the Augmented Alzheimer MRI Dataset, which is an augmented version of the Alzheimer’s Dataset (4 class of Images), the Brain Tumor MRI Dataset, and the NTUA Parkinson Dataset.\n","\n","***The following URL is for accessing and using the dataset:*** Encephalon_Dataset, https://drive.google.com/drive/folders/16bqDxOEimwF4ASa_e52PIC48XQX6oNAp?usp=sharing.\n","\n","*If you could not access the dataset through the link, feel free to e-mail us on the following e-mail addresses for help:*\n","\n","\n","1.   ladyaouto@gmail.com\n","2.   leen.aouto@gmail.com\n","3.   rawan.flifel66@gmail.com\n","\n","---\n"],"metadata":{"id":"AxHSF3HG4dB1"}},{"cell_type":"markdown","source":["## **Step 1:** Mounting Google Drive"],"metadata":{"id":"lSSbUc0-4c8Y"}},{"cell_type":"markdown","source":["Mounting Google Drive files to read the dataset."],"metadata":{"id":"QAKkFXVV4w6s"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrkcIjr0a_ok"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"jiq-i9pNbuwK"},"source":["## **Step 2:** Importing dependencies"]},{"cell_type":"markdown","metadata":{"id":"0XYHszlD8Xzq"},"source":["Importing all the necessary libraries including Keras, Tensorflow, NumPy, Matplotlib, Sklearn, and more."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1QkZuMLpeDps"},"outputs":[],"source":["import keras\n","import os\n","import operator\n","import time\n","import itertools\n","import sklearn\n","import sys\n","import random\n","import numpy as np\n","import tensorflow as tf\n","import seaborn as sns\n","import pandas as pd\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.metrics import confusion_matrix\n","from keras.optimizers import Adam\n","from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n","from keras.applications.vgg16 import VGG16\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","from tensorflow.keras.applications.vgg16 import decode_predictions\n","from PIL import Image\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"zHW9Yxhmc6RI"},"source":["## **Step 3:** Data preprocessing"]},{"cell_type":"markdown","metadata":{"id":"SuM4HzNyeJYm"},"source":["**(a)** Augmenting data using *ImageDataGenerator* class and reading data using *flow_from_directory* mathod."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MlutkdZXc6mO"},"outputs":[],"source":["train_path = '/content/drive/MyDrive/Brain_Diseases_Classification/Datasets/Encephalon_Dataset/Training/Level2'\n","test_path = '/content/drive/MyDrive/Brain_Diseases_Classification/Datasets/Encephalon_Dataset/Testing/Level2'\n","\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   rotation_range = 40,\n","                                   width_shift_range = 0.2,\n","                                   height_shift_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","print(\"Training set:\")\n","training_set = train_datagen.flow_from_directory(train_path,\n","                                                 target_size = (224, 224),\n","                                                 batch_size = 64,\n","                                                 class_mode = 'categorical')\n","\n","print(\"---------------------------\")\n","\n","print(\"Testing set:\")\n","test_set = test_datagen.flow_from_directory(test_path,\n","                                            target_size = (224, 224),\n","                                            batch_size = 64,\n","                                            class_mode = 'categorical',\n","                                            shuffle=False)"]},{"cell_type":"markdown","source":["**(b)** Printing count of each class in the target path of training and testing sets."],"metadata":{"id":"D0gMvqqR5of8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"03aOwOOgrWfz"},"outputs":[],"source":["total_train = 0\n","total_test = 0\n","\n","print(\"Training Count:\")\n","for c in os.listdir(train_path):\n","    print(\"class ({}) has {} images.\".format(c, len(os.listdir(os.path.join(train_path, c)))))\n","    total_train += len(os.listdir(os.path.join(train_path, c)))\n","print(\"---------------------------\")\n","\n","print(\"Testing Count:\")\n","for c in os.listdir(test_path):\n","    print(\"class ({}) has {} images.\".format(c, len(os.listdir(os.path.join(test_path, c)))))\n","    total_test += len(os.listdir(os.path.join(test_path, c)))\n","print(\"---------------------------\")\n","\n","print(\"Total Training Images:\", total_train)\n","print(\"Total Testing Images:\", total_test)"]},{"cell_type":"markdown","metadata":{"id":"n3vF54FNh3V4"},"source":["**(c)** Visualizing data count of the training set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8riVFeyth7OY"},"outputs":[],"source":["LABELS = ['Alzhiemer', 'Parkinson', 'Tumor']\n","nimgs={}\n","for i in LABELS:\n","  nimages=len(os.listdir(train_path+'/'+i))\n","  nimgs[i]=nimages\n","plt.figure(figsize=(6, 3))\n","plt.bar(range(len(nimgs)), list(nimgs.values()), align='center')\n","plt.xticks(range(len(nimgs)), list(nimgs.keys()))\n","plt.title('Distribution of different classes in Training Dataset')\n","plt.show()\n"]},{"cell_type":"markdown","source":["**(d)** Displaying data samples."],"metadata":{"id":"oqBFX9__5yoU"}},{"cell_type":"code","source":["def display_sample_images(folder_path):\n","    for subfolder in os.listdir(folder_path):\n","        folder_images = []\n","        subfolder_path = os.path.join(folder_path, subfolder)\n","\n","        for image_file in os.listdir(subfolder_path):\n","            if image_file.endswith(('.jpg', '.png')):\n","                folder_images.append(os.path.join(subfolder_path, image_file))\n","\n","        plt.figure(figsize=(10, 3))\n","        plt.suptitle(f\"Sample Images of {subfolder}\", fontsize=18)\n","        plt.axis('off')\n","\n","        num_images_to_display = min(4, len(folder_images))\n","        random_images = random.sample(folder_images, num_images_to_display)\n","\n","        for i, image_path in enumerate(random_images, start=1):\n","            plt.subplot(1, num_images_to_display, i)\n","            img = Image.open(image_path)\n","            img = img.convert(\"RGB\")\n","            plt.imshow(img)\n","            plt.axis('off')\n","\n","        plt.show()\n","\n","\n","display_sample_images(train_path)"],"metadata":{"id":"nveA5KMj5z71"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mucFGldv9VGP"},"source":["## **Step 4:** Implementating VGG16"]},{"cell_type":"markdown","metadata":{"id":"iT1ii4twt3iN"},"source":["**(a)** Downloading the model, then printing a summary and a visual architecture of it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BCizxdsZrylK"},"outputs":[],"source":["vgg16 = VGG16(include_top=False,\n","    weights=\"imagenet\",\n","    input_tensor=Input(shape=(224, 224, 3))\n","    )\n","vgg16.summary()\n","keras.utils.plot_model(vgg16, \"/content/drive/MyDrive/Colab Notebooks/Model_Plots/VGG16_Standard.png\")"]},{"cell_type":"markdown","metadata":{"id":"lsXdkr_r9UtE"},"source":["**(b)** Adding customized output layers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xhNqq4HjyVKp"},"outputs":[],"source":["# Freeze the layers\n","for layer in vgg16.layers:\n","  layer.trainable = False\n","\n","x = Flatten()(vgg16.output)\n","prediction = tf.keras.layers.Dense(3, activation='softmax')(x)\n","model = Model(inputs=vgg16.input, outputs=prediction)"]},{"cell_type":"markdown","metadata":{"id":"jH_fTaw5-CmI"},"source":["**(c)** Defining the metrics array."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lYyvBKErOtFY"},"outputs":[],"source":["METRICS = [\n","      keras.metrics.TruePositives(name='tp'),\n","      keras.metrics.FalsePositives(name='fp'),\n","      keras.metrics.TrueNegatives(name='tn'),\n","      keras.metrics.FalseNegatives(name='fn'),\n","      keras.metrics.CategoricalAccuracy(name='accuracy'),\n","      keras.metrics.Precision(name='precision'),\n","      keras.metrics.Recall(name='recall'),\n","      keras.metrics.AUC(name='auc'),\n","      keras.metrics.AUC(name='prc', curve='PR')\n","]"]},{"cell_type":"markdown","metadata":{"id":"H71FoODt-QTX"},"source":["**(d)** Compiling the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HY2sZssvO3Ff"},"outputs":[],"source":["model.compile(loss='categorical_crossentropy', optimizer= 'adam' ,metrics=[METRICS])"]},{"cell_type":"markdown","source":["**(e)** Printing model summary and visual architecture after the added output layes."],"metadata":{"id":"K1g9U8pi8pa8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJ_ifB02OjHL"},"outputs":[],"source":["model.summary()\n","keras.utils.plot_model(model, \"/content/drive/MyDrive/Colab Notebooks/Model_Plots/VGG16_Customized.png\")"]},{"cell_type":"markdown","metadata":{"id":"cpy4_l_aI-hA"},"source":["# **Step 5**: Training and testing the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p53TV9WqEux6"},"outputs":[],"source":["checkpoint = ModelCheckpoint('VGG16_checkpoint_L2.h5', monitor='val_accuracy',\n","                             verbose=1,\n","                             save_best_only=True,\n","                             save_weights_only=False,\n","                             mode='auto')\n","\n","early = EarlyStopping(monitor='val_loss',\n","                      min_delta=0,\n","                      patience=20,\n","                      verbose=1,\n","                      mode='auto')\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n","                           patience=5, mode='min', verbose=1,\n","                           min_lr=1e-5)\n","\n","vgg16_classifier = model.fit(\n","    training_set,\n","    validation_data=test_set,\n","    epochs=10,\n","    steps_per_epoch=len(training_set),\n","    validation_steps=len(test_set),\n","    verbose = True,\n","    callbacks=[checkpoint, early, reduce_lr]\n","    )"]},{"cell_type":"markdown","metadata":{"id":"qV9L0FvyvPC0"},"source":["# **Step 6:** Saving the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zETsYg1PPkqR"},"outputs":[],"source":["model.save('/content/drive/MyDrive/Colab Notebooks/Model/VGG16.h5')\n","print(\"Model was saved.\")"]},{"cell_type":"markdown","metadata":{"id":"Xp0OusB_CFnh"},"source":["# **Step 7:** Evaluating Results\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TtAW2Qwaw59e"},"source":["**(a)** Plotting Loss and Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EzESx7RMKNsi"},"outputs":[],"source":["plt.figure(figsize=(12, 8))\n","\n","# Loss\n","plt.subplot(2, 2, 1)\n","plt.plot(vgg16_classifier.history['loss'], label='Loss')\n","plt.plot(vgg16_classifier.history['val_loss'], label='Val_Loss')\n","plt.legend()\n","plt.title('Loss Evolution')\n","plt.savefig('loss.png')\n","\n","# Accuracy\n","plt.subplot(2, 2, 2)\n","plt.plot(vgg16_classifier.history['accuracy'], label='Accuracy')\n","plt.plot(vgg16_classifier.history['val_accuracy'], label='Val_Accuracy')\n","plt.legend()\n","plt.title('Accuracy Evolution')\n","plt.savefig('accuracy.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XYLZ26d04V-D"},"outputs":[],"source":["# Accuracy\n","acc = vgg16_classifier.history['accuracy']\n","epochs = range(1, len(acc) + 1)\n","val_acc = vgg16_classifier.history['val_accuracy']\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'r', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend(loc='lower right')\n","plt.grid()\n","\n","plt.savefig('acc.png')\n","plt.figure(figsize=(12, 8))\n","plt.show()\n","\n","# Loss\n","loss = vgg16_classifier.history['loss']\n","val_loss = vgg16_classifier.history['val_loss']\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend(loc='upper right')\n","plt.grid()\n","\n","plt.savefig('loss.png')\n","plt.figure(figsize=(12, 8))\n","plt.show()"]},{"cell_type":"markdown","source":["**(b)** Visualizing more metrics."],"metadata":{"id":"GZua8kHE-y2y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFWnzMHrHuYe"},"outputs":[],"source":["def plot_metrics(history):\n","  metrics =  ['loss', 'auc', 'precision', 'recall', 'accuracy']\n","  mpl.rcParams['figure.figsize'] = (12, 10)\n","  colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n","  for n, metric in enumerate(metrics):\n","    name = metric.replace(\"_\",\" \").capitalize()\n","    plt.subplot(3,2,n+1)\n","    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n","    plt.plot(history.epoch, history.history['val_'+metric],\n","             color=colors[0], linestyle=\"--\", label='Val')\n","    plt.xlabel('Epoch')\n","    plt.ylabel(name)\n","    if metric == 'loss':\n","      plt.ylim([0, plt.ylim()[1]])\n","    elif metric == 'auc':\n","      plt.ylim([0.8,1])\n","    elif metric == 'accuracy':\n","      plt.ylim([0,1])\n","    else:\n","      plt.ylim([0,1])\n","\n","    plt.legend()\n","\n","\n","plot_metrics(vgg16_classifier)"]},{"cell_type":"markdown","metadata":{"id":"A8orz7V55dmr"},"source":["**(c)** Plotting Confusion Matrix."]},{"cell_type":"code","source":["val_accuracy = model.evaluate(test_set)"],"metadata":{"id":"nki_d7wxAarG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Getting true labels and predicted labels."],"metadata":{"id":"4zJARFm3_Nau"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QPI-gG3LRpeu"},"outputs":[],"source":["predictions = model.predict(test_set, verbose=1)\n","predicted_labels = np.argmax(predictions, axis=1)\n","\n","true_labels = test_set.classes"]},{"cell_type":"markdown","source":["Calculating and printing the confusion matrix and the classification report."],"metadata":{"id":"ZrrvGY1p_kF8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2IiDNw4bRz5s"},"outputs":[],"source":["confusion_mat = confusion_matrix(true_labels, predicted_labels)\n","print(confusion_mat)\n","\n","print(\"\\n-----------------------------------------------------------\\n\")\n","\n","target_names = ['Alzhiemer', 'Parkinson', 'Tumor']\n","print('Classification Report')\n","print(classification_report(true_labels, predicted_labels, target_names=target_names))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OD2Ay_wvf0eY"},"outputs":[],"source":["def plot_confusion_matrix(cm,\n","                          target_names,\n","                          title='Confusion matrix',\n","                          cmap=None,\n","                          normalize=True):\n","\n","    accuracy = np.trace(cm) / float(np.sum(cm))\n","    misclass = 1 - accuracy\n","\n","    if cmap is None:\n","        cmap = plt.get_cmap('Blues')\n","\n","    plt.figure(figsize=(9, 6))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","\n","    if target_names is not None:\n","        tick_marks = np.arange(len(target_names))\n","        plt.xticks(tick_marks, target_names, rotation=45)\n","        plt.yticks(tick_marks, target_names)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","\n","    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if normalize:\n","            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","        else:\n","            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n","    plt.show()\n","\n","plot_confusion_matrix(confusion_mat, target_names=target_names, title=\"confusion matrix\")"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6WibzgzauvW"
      },
      "source": [
        "#**Encephalon Diseases Classifier**\n",
        "Is a multi-level project where more than one step of classification is performed on a dataset that contains MRI scans of control subjets, Alzheimer's disease, Parkinson's disease, and brain tumors.\n",
        "\n",
        "---\n",
        "\n",
        "##**Encephalon Dataset**\n",
        "The dataset used in this project is a combintion of three different datasets. These datasets are the Augmented Alzheimer MRI Dataset, which is an augmented version of the Alzheimerâ€™s Dataset (4 class of Images), the Brain Tumor MRI Dataset, and the NTUA Parkinson Dataset.\n",
        "\n",
        "***The following URL is for accessing and using the dataset:*** Encephalon_Dataset, https://drive.google.com/drive/folders/16bqDxOEimwF4ASa_e52PIC48XQX6oNAp?usp=sharing.\n",
        "\n",
        "*If you could not access the dataset through the link, feel free to e-mail us on the following e-mail addresses for help:*\n",
        "\n",
        "\n",
        "1.   ladyaouto@gmail.com\n",
        "2.   leen.aouto@gmail.com\n",
        "3.   rawan.flifel66@gmail.com\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeJFCbIObSgD"
      },
      "source": [
        "## **Step 1:** Mounting Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6beQEe8Wa-yu"
      },
      "source": [
        "Mounting Google Drive files to read the dataset .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrkcIjr0a_ok"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiq-i9pNbuwK"
      },
      "source": [
        "## **Step 2:** Importing dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XYHszlD8Xzq"
      },
      "source": [
        "Importing all the necessary libraries including Keras, Tensorflow, NumPy, Matplotlib, Sklearn, and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QkZuMLpeDps"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "import os\n",
        "import keras\n",
        "import pathlib\n",
        "import itertools\n",
        "import random\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from PIL import Image\n",
        "from os import path, environ\n",
        "from glob import glob\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHW9Yxhmc6RI"
      },
      "source": [
        "## **Step 3:** Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuM4HzNyeJYm"
      },
      "source": [
        "**(a)** Augmenting data using *ImageDataGenerator* class and reading data using *flow_from_directory* mathod."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlutkdZXc6mO"
      },
      "outputs": [],
      "source": [
        "train_path = '/content/drive/MyDrive/Brain_Diseases_Classification/Datasets/Encephalon_Dataset/Training/Level1'\n",
        "test_path = '/content/drive/MyDrive/Brain_Diseases_Classification/Datasets/Encephalon_Dataset/Testing/Level1'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "print(\"Training set:\")\n",
        "training_set = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 64,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "print(\"---------------------------\")\n",
        "\n",
        "print(\"Testing set:\")\n",
        "test_set = test_datagen.flow_from_directory(test_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 64,\n",
        "                                            class_mode = 'categorical',\n",
        "                                            shuffle=False\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(b)** Printing count of each class in the target path of training and testing sets."
      ],
      "metadata": {
        "id": "VMiLjc7vnaSI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYQ4rKLmMdJg"
      },
      "outputs": [],
      "source": [
        "total_train = 0\n",
        "total_test = 0\n",
        "\n",
        "print(\"Training Count:\")\n",
        "for c in os.listdir(train_path):\n",
        "    print(\"class ({}) has {} images.\".format(c, len(os.listdir(os.path.join(train_path, c)))))\n",
        "    total_train += len(os.listdir(os.path.join(train_path, c)))\n",
        "print(\"---------------------------\")\n",
        "\n",
        "print(\"Testing Count:\")\n",
        "for c in os.listdir(test_path):\n",
        "    print(\"class ({}) has {} images.\".format(c, len(os.listdir(os.path.join(test_path, c)))))\n",
        "    total_test += len(os.listdir(os.path.join(test_path, c)))\n",
        "print(\"---------------------------\")\n",
        "\n",
        "print(\"Total Training Images:\", total_train)\n",
        "print(\"Total Testing Images:\", total_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3vF54FNh3V4"
      },
      "source": [
        "**(c)** Visualizing data count of the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8riVFeyth7OY"
      },
      "outputs": [],
      "source": [
        "LABELS = ['Healthy', 'Diseased']\n",
        "nimgs={}\n",
        "for i in LABELS:\n",
        "  nimages=len(os.listdir(train_path+'/'+i))\n",
        "  nimgs[i]=nimages\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.bar(range(len(nimgs)), list(nimgs.values()), align='center')\n",
        "plt.xticks(range(len(nimgs)), list(nimgs.keys()))\n",
        "plt.title('Distribution of different classes of the Training set')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(d)** Displaying data samples."
      ],
      "metadata": {
        "id": "V7uuPqkJoPnn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pPUEjNik6G6"
      },
      "outputs": [],
      "source": [
        "def display_sample_images(folder_path):\n",
        "    for subfolder in os.listdir(folder_path):\n",
        "        folder_images = []\n",
        "        subfolder_path = os.path.join(folder_path, subfolder)\n",
        "\n",
        "        for image_file in os.listdir(subfolder_path):\n",
        "            if image_file.endswith(('.jpg', '.png')):\n",
        "                folder_images.append(os.path.join(subfolder_path, image_file))\n",
        "\n",
        "        plt.figure(figsize=(10, 3))\n",
        "        plt.suptitle(f\"Sample Images of {subfolder}\", fontsize=18)\n",
        "        plt.axis('off')\n",
        "\n",
        "        num_images_to_display = min(4, len(folder_images))\n",
        "        random_images = random.sample(folder_images, num_images_to_display)\n",
        "\n",
        "        for i, image_path in enumerate(random_images, start=1):\n",
        "            plt.subplot(1, num_images_to_display, i)\n",
        "            img = Image.open(image_path)\n",
        "            img = img.convert(\"RGB\")\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "display_sample_images(train_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfpheo7BmWjq"
      },
      "source": [
        "## **Step 4:** Implementating ResNet152V2\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd_hMIqMmWjr"
      },
      "source": [
        "**(a)** Downloading the model, then printing a summary and a visual architecture of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8KwgsyFmWjs"
      },
      "outputs": [],
      "source": [
        "resnet152V2 = ResNet152V2(\n",
        "                 include_top=False,\n",
        "                 weights='imagenet',\n",
        "                 input_tensor=Input(shape=(224, 224, 3)))\n",
        "resnet152V2.summary()\n",
        "keras.utils.plot_model(resnet152V2, \"/content/drive/MyDrive/Colab Notebooks/ResNet152_Standard.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(b)** Adding customized output layers."
      ],
      "metadata": {
        "id": "Im8EC4ZYpNd8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zD0JKY8mmWjt"
      },
      "outputs": [],
      "source": [
        "model = resnet152V2.output\n",
        "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
        "model = Dense(128, activation='relu')(model)\n",
        "predictions = Dense(2, activation='softmax')(model)\n",
        "model = Model(inputs=resnet152V2.input, outputs=predictions)\n",
        "\n",
        "# Unfreeze the layers\n",
        "for layer in model.layers[0:]:\n",
        " layer.trainable = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwkZLxRzmWjt"
      },
      "source": [
        "**(c)** Defining the metrics array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tF_RUr-mWjt"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'),\n",
        "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj76vn2dmWju"
      },
      "source": [
        "**(d)** Compiling the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS0IssaBmWju"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer= 'adam' ,metrics=[METRICS])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(e)** Printing model summary and visual architecture after the added output layes."
      ],
      "metadata": {
        "id": "SGK6R1oQp8hL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuh8GljwmWju"
      },
      "outputs": [],
      "source": [
        "model.summary()\n",
        "keras.utils.plot_model(model, \"/content/drive/MyDrive/Colab Notebooks/ResNet152_Customized.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpy4_l_aI-hA"
      },
      "source": [
        "# **Step 5**: Training and testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p53TV9WqEux6"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint('resnet152V2_checkpoint_v1_stg3_2.h5', monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=False,\n",
        "                             mode='auto')\n",
        "\n",
        "early = EarlyStopping(monitor='val_loss',\n",
        "                      min_delta=0,\n",
        "                      patience=20,\n",
        "                      verbose=1,\n",
        "                      mode='auto')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                           patience=5, mode='min', verbose=1,\n",
        "                           min_lr=1e-5)\n",
        "\n",
        "resnet152V2_classifier = model.fit(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs = 10,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set),\n",
        "  verbose = True,\n",
        "  callbacks=[checkpoint,\n",
        "             #early,\n",
        "             reduce_lr])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJgLsgk_mpHe"
      },
      "source": [
        "# **Step 6:** Saving the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8kiAniGmpHf"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/Model/Level1_10E_Resnet152V2.h5')\n",
        "print(\"Model was saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp0OusB_CFnh"
      },
      "source": [
        "# **Step 7:** Evaluating Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtAW2Qwaw59e"
      },
      "source": [
        "**(a)** Plotting Loss and Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzESx7RMKNsi"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "#Loss\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(resnet152V2_classifier.history['loss'], label='Loss')\n",
        "plt.plot(resnet152V2_classifier.history['val_loss'], label='Val_Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Evolution')\n",
        "plt.savefig('loss.png')\n",
        "\n",
        "#Accuracy\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(resnet152V2_classifier.history['accuracy'], label='Accuracy')\n",
        "plt.plot(resnet152V2_classifier.history['val_accuracy'], label='Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Evolution')\n",
        "plt.savefig('accuracy.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYLZ26d04V-D"
      },
      "outputs": [],
      "source": [
        "#accuracy\n",
        "acc = resnet152V2_classifier.history['accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "val_acc = resnet152V2_classifier.history['val_accuracy']\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "\n",
        "plt.savefig('acc.png')\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.show()\n",
        "\n",
        "#loss\n",
        "loss = resnet152V2_classifier.history['loss']\n",
        "val_loss = resnet152V2_classifier.history['val_loss']\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "\n",
        "plt.savefig('loss.png')\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(b)** Visualizing more metrics."
      ],
      "metadata": {
        "id": "9wxP2TFqr_Ul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWnzMHrHuYe"
      },
      "outputs": [],
      "source": [
        "def plot_metrics(history):\n",
        "  metrics =  ['loss', 'auc', 'precision', 'recall', 'accuracy']\n",
        "  mpl.rcParams['figure.figsize'] = (12, 10)\n",
        "  colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.subplot(3,2,n+1)\n",
        "    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
        "    plt.plot(history.epoch, history.history['val_'+metric],\n",
        "             color=colors[0], linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    if metric == 'loss':\n",
        "      plt.ylim([0, plt.ylim()[1]])\n",
        "    elif metric == 'auc':\n",
        "      plt.ylim([0.8,1])\n",
        "    elif metric == 'accuracy':\n",
        "      plt.ylim([0,1])\n",
        "    else:\n",
        "      plt.ylim([0,1])\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "plot_metrics(resnet152V2_classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRcVzTjIN6N9"
      },
      "source": [
        "**(c)** Plotting Confusion Matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM48IuobOHmZ"
      },
      "outputs": [],
      "source": [
        "val_accuracy = model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting true labels and predicted labels."
      ],
      "metadata": {
        "id": "5cxl9RdetFLA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFfc5AM5OL0_"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_set, verbose=1)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "true_labels = test_set.classes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating and printing the confusion matrix and the classification report."
      ],
      "metadata": {
        "id": "Ynu0yn7JtRcR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmZSgi_jOQgM"
      },
      "outputs": [],
      "source": [
        "confusion_mat = confusion_matrix(true_labels, predicted_labels)\n",
        "print(confusion_mat)\n",
        "\n",
        "print(\"\\n-----------------------------------------------------------\\n\")\n",
        "\n",
        "target_names = ['Healthy', 'Diseased']\n",
        "print('Classification Report')\n",
        "print(classification_report(true_labels, predicted_labels, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8cRYiVtFH6V"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(9, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plot_confusion_matrix(confusion_mat, target_names=target_names, title=\"confusion matrix\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
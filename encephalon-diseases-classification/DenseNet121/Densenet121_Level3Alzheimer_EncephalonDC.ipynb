{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6WibzgzauvW"
      },
      "source": [
        "#**Encephalon Diseases Classifier**\n",
        "Is a multi-level project where more than one step of classification is performed on a dataset that contains MRI scans of control subjets, Alzheimer's disease, Parkinson's disease, and brain tumors.\n",
        "\n",
        "---\n",
        "\n",
        "##**Encephalon Dataset**\n",
        "The dataset used in this project is a combintion of three different datasets. These datasets are the Augmented Alzheimer MRI Dataset, which is an augmented version of the Alzheimerâ€™s Dataset (4 class of Images), the Brain Tumor MRI Dataset, and the NTUA Parkinson Dataset.\n",
        "\n",
        "***The following URL is for accessing and using the dataset:*** Encephalon_Dataset, https://drive.google.com/drive/folders/16bqDxOEimwF4ASa_e52PIC48XQX6oNAp?usp=sharing.\n",
        "\n",
        "*If you could not access the dataset through the link, feel free to e-mail us on the following e-mail addresses for help:*\n",
        "\n",
        "\n",
        "1.   ladyaouto@gmail.com\n",
        "2.   leen.aouto@gmail.com\n",
        "3.   rawan.flifel66@gmail.com\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeJFCbIObSgD"
      },
      "source": [
        "## **Step 1:** Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrkcIjr0a_ok"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiq-i9pNbuwK"
      },
      "source": [
        "## **Step 2:** Importing dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XYHszlD8Xzq"
      },
      "source": [
        "Importing all the necessary libraries including Keras, Tensorflow, NumPy, Matplotlib, Sklearn, and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QkOyDGwaoT4"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow\n",
        "import os\n",
        "import operator\n",
        "import time\n",
        "import itertools\n",
        "import sys\n",
        "import sklearn\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.densenet import preprocess_input\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import Input, Add, Dense,GlobalAvgPool2D, Concatenate, AvgPool2D, Dropout, ReLU, Activation, MaxPool2D, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, GlobalAveragePooling2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.densenet import preprocess_input, decode_predictions\n",
        "from PIL import Image\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHW9Yxhmc6RI"
      },
      "source": [
        "## **Step 3:** Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuM4HzNyeJYm"
      },
      "source": [
        "**(a)** Augmenting data using *ImageDataGenerator* class and reading data using *flow_from_directory* mathod."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlutkdZXc6mO"
      },
      "outputs": [],
      "source": [
        "train_path = '/content/drive/MyDrive/Brain_Diseases_Classification/Datasets/Encephalon_Dataset/Training/Level3/Tumor'\n",
        "test_path = '/content/drive/MyDrive/Brain_Diseases_Classification/Datasets/Encephalon_Dataset/Testing/Level3/Tumor'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "print(\"Training set:\")\n",
        "training_set = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 64,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "print(\"---------------------------\")\n",
        "\n",
        "print(\"Testing set:\")\n",
        "test_set = test_datagen.flow_from_directory(test_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 64,\n",
        "                                            class_mode = 'categorical',\n",
        "                                            shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(b)** Printing count of each class in the target path of training and testing sets."
      ],
      "metadata": {
        "id": "2H0_heM8grba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03aOwOOgrWfz"
      },
      "outputs": [],
      "source": [
        "total_train = 0\n",
        "total_test = 0\n",
        "\n",
        "print(\"Training Count:\")\n",
        "for c in os.listdir(train_path):\n",
        "    print(\"class ({}) has {} images.\".format(c, len(os.listdir(os.path.join(train_path, c)))))\n",
        "    total_train += len(os.listdir(os.path.join(train_path, c)))\n",
        "print(\"---------------------------\")\n",
        "\n",
        "print(\"Testing Count:\")\n",
        "for c in os.listdir(test_path):\n",
        "    print(\"class ({}) has {} images.\".format(c, len(os.listdir(os.path.join(test_path, c)))))\n",
        "    total_test += len(os.listdir(os.path.join(test_path, c)))\n",
        "print(\"---------------------------\")\n",
        "\n",
        "print(\"Total Training Images:\", total_train)\n",
        "print(\"Total Testing Images:\", total_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3vF54FNh3V4"
      },
      "source": [
        "**(c)** Visualizing data count of the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8riVFeyth7OY"
      },
      "outputs": [],
      "source": [
        "LABELS = ['Glioma', 'Meningioma', 'Pituitary']\n",
        "nimgs={}\n",
        "for i in LABELS:\n",
        "  nimages=len(os.listdir(train_path+'/'+i))\n",
        "  nimgs[i]=nimages\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.bar(range(len(nimgs)), list(nimgs.values()), align='center')\n",
        "plt.xticks(range(len(nimgs)), list(nimgs.keys()))\n",
        "plt.title('Distribution of different classes in Training Dataset')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(d)** Displaying data samples."
      ],
      "metadata": {
        "id": "IIA4M-Q2hYEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_sample_images(folder_path):\n",
        "    for subfolder in os.listdir(folder_path):\n",
        "        folder_images = []\n",
        "        subfolder_path = os.path.join(folder_path, subfolder)\n",
        "\n",
        "        for image_file in os.listdir(subfolder_path):\n",
        "            if image_file.endswith(('.jpg', '.png')):\n",
        "                folder_images.append(os.path.join(subfolder_path, image_file))\n",
        "\n",
        "        plt.figure(figsize=(10, 3))\n",
        "        plt.suptitle(f\"Sample Images of {subfolder}\", fontsize=18)\n",
        "        plt.axis('off')\n",
        "\n",
        "        num_images_to_display = min(4, len(folder_images))\n",
        "        random_images = random.sample(folder_images, num_images_to_display)\n",
        "\n",
        "        for i, image_path in enumerate(random_images, start=1):\n",
        "            plt.subplot(1, num_images_to_display, i)\n",
        "            img = Image.open(image_path)\n",
        "            img = img.convert(\"RGB\")\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "display_sample_images(train_path)"
      ],
      "metadata": {
        "id": "GW5HKAU0hdyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mucFGldv9VGP"
      },
      "source": [
        "## **Step 4:** Implementating DenseNet121\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(a)** Downloading the model, then printing a summary and a visual architecture of it."
      ],
      "metadata": {
        "id": "ZQqkKwZBhsPk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7EAgb1NgKRP"
      },
      "outputs": [],
      "source": [
        "DenseN = tf.keras.applications.densenet.DenseNet121(include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=Input(shape=(224, 224, 3))\n",
        "    )\n",
        "keras.utils.plot_model(DenseN, \"/content/drive/MyDrive/Colab Notebooks/DenseNet121_Standard.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgpyI7K9goGE"
      },
      "source": [
        "**(b)** Adding customized output layers.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weGAKie8g21P"
      },
      "outputs": [],
      "source": [
        "# Freeze the layers\n",
        "for layer in DenseN.layers[:-9]:\n",
        "    layer.trainable= False\n",
        "\n",
        "x= DenseN.layers[-3].output\n",
        "x= GlobalAveragePooling2D()(x)\n",
        "x= BatchNormalization()(x)\n",
        "x= Dropout(0.5)(x)\n",
        "x= Dense(1024,activation='relu')(x)\n",
        "x= Dense(512,activation='relu')(x)\n",
        "x= BatchNormalization()(x)\n",
        "x= Dropout(0.5)(x)\n",
        "\n",
        "predictions= Dense(3, activation = 'softmax')(x)\n",
        "model= Model(inputs= DenseN.input, outputs= predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(c)** Defining the metrics array."
      ],
      "metadata": {
        "id": "6VAKsAdels27"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYyvBKErOtFY"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'),\n",
        "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR')\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(d)** Compiling the model."
      ],
      "metadata": {
        "id": "QrDX4F6xl1eP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY2sZssvO3Ff"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer= 'adam' ,metrics=[METRICS])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(e)** Printing model summary and visual architecture after the added output layes."
      ],
      "metadata": {
        "id": "mO-hMS2DmKti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "keras.utils.plot_model(model, \"/content/drive/MyDrive/Colab Notebooks/Model_Plots/DenseNet121_Customized.png\")"
      ],
      "metadata": {
        "id": "BMT4kkj9BUGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBPKvj4ohGwy"
      },
      "source": [
        "# **Step 5**: Training and testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGx7a_3bpREz"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint('Densenet121_checkpoint_S3.h5', monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=False,\n",
        "                             mode='auto')\n",
        "\n",
        "early = EarlyStopping(monitor='val_loss',\n",
        "                      min_delta=0,\n",
        "                      patience=20,\n",
        "                      verbose=1,\n",
        "                      mode='auto')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                           patience=5, mode='min', verbose=1,\n",
        "                           min_lr=1e-5)\n",
        "\n",
        "Densenet121_classifier = model.fit(\n",
        "  training_set,\n",
        "  validation_data= test_set,\n",
        "  epochs=10,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set),\n",
        "  verbose = True,\n",
        "  callbacks=[checkpoint, early, reduce_lr]\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV9L0FvyvPC0"
      },
      "source": [
        "# **Step 6:** Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ig3PMPmW-Yxy"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/Model/Densenet121.h5')\n",
        "print(\"Model was saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 7:** Evaluating Results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aYw_v0Zvd6lo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(a)** Plotting Loss and Accuracy"
      ],
      "metadata": {
        "id": "TDCUc2e9o1B7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Loss\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(Densenet121_classifier.history['loss'], label='Loss')\n",
        "plt.plot(Densenet121_classifier.history['val_loss'], label='Val_Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Evolution')\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(Densenet121_classifier.history['accuracy'], label='Accuracy')\n",
        "plt.plot(Densenet121_classifier.history['val_accuracy'], label='Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Evolution')"
      ],
      "metadata": {
        "id": "t1cntPcQd_QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "acc = Densenet121_classifier.history['accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "val_acc = Densenet121_classifier.history['val_accuracy']\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "\n",
        "plt.savefig('acc.png')\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.show()\n",
        "\n",
        "# Loss\n",
        "loss = Densenet121_classifier.history['loss']\n",
        "val_loss = Densenet121_classifier.history['val_loss']\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "\n",
        "plt.savefig('loss.png')\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MFw4U2sbeJzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(b)** Visualizing more metrics."
      ],
      "metadata": {
        "id": "ZgN3edAMpWv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(history):\n",
        "  metrics =  ['loss', 'auc', 'precision', 'recall', 'accuracy']\n",
        "  mpl.rcParams['figure.figsize'] = (12, 10)\n",
        "  colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.subplot(3,2,n+1)\n",
        "    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
        "    plt.plot(history.epoch, history.history['val_'+metric],\n",
        "             color=colors[0], linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    if metric == 'loss':\n",
        "      plt.ylim([0, plt.ylim()[1]])\n",
        "    elif metric == 'auc':\n",
        "      plt.ylim([0.8,1])\n",
        "    elif metric == 'accuracy':\n",
        "      plt.ylim([0,1])\n",
        "    else:\n",
        "      plt.ylim([0,1])\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "plot_metrics(Densenet121_classifier)"
      ],
      "metadata": {
        "id": "k_6jvoiseeP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(c)** Plotting Confusion Matrix."
      ],
      "metadata": {
        "id": "w5O5Tk9fewmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_accuracy = model.evaluate(test_set)"
      ],
      "metadata": {
        "id": "Bgmq6SnWRXIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting true labels and predicted labels."
      ],
      "metadata": {
        "id": "xSD8Aq2ZpqJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_set, verbose=1)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "true_labels = test_set.classes"
      ],
      "metadata": {
        "id": "2saNNiPIRY2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating and printing the confusion matrix and the classification report."
      ],
      "metadata": {
        "id": "Jl41iE-Up1no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_mat = confusion_matrix(true_labels, predicted_labels)\n",
        "print(confusion_mat)\n",
        "\n",
        "print(\"\\n-----------------------------------------------------------\\n\")\n",
        "\n",
        "target_names = ['Glioma', 'Meningioma', 'Pituitary']\n",
        "print('Classification Report')\n",
        "print(classification_report(true_labels, predicted_labels, target_names=target_names))"
      ],
      "metadata": {
        "id": "d1HyI0SHReMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(9, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_confusion_matrix(confusion_mat, target_names=target_names, title=\"confusion matrix\")"
      ],
      "metadata": {
        "id": "x8cRYiVtFH6V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}